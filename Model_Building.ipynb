{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Building.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnsNOr0Uk6M6"
      },
      "outputs": [],
      "source": [
        "clf = ensemble.RandomForestClassifier(\n",
        "#     max_depth=2, \n",
        "    random_state=0,\n",
        "    n_estimators = 100,\n",
        "    n_jobs = -1\n",
        ")\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X_train, y_train)\n",
        "train = best.score(X_train, y_train)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Get test accuracy\n",
        "    \n",
        "    test = best.score(X=X_test,y=y_test)\n",
        "    print(\"\\nTest Accuracy Score:\",test)\n",
        "    \n",
        "    y_pred = best.predict(X_test)\n",
        "    print(y_pred)\n",
        "    ari = adjusted_rand_score(y_test, y_pred)\n",
        "    print(\"\\nAdjusted Rand-Index: %.3f\" % ari)\n",
        "    \n",
        "    hom = homogeneity_score(y_test,y_pred)\n",
        "    print(\"Homogeneity Score: %.3f\" % hom)\n",
        "    \n",
        "    sil = silhouette_score(X_test,y_pred)\n",
        "    print(\"Silhouette Score: %.3f\" % sil)\n",
        "    \n",
        "    nmi = normalized_mutual_info_score(y_test,y_pred)\n",
        "    print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
        "\n",
        "    #print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "F9_bVYnwlCCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1000 ROWS, 0.01 SMALLER STOPWARDS\n",
        "1500 ROWS\n",
        "0.9769651268015053\n",
        "\n",
        "Train Accuracy Score: 0.9712628865979381\n",
        "\n",
        "Test Accuracy Score: 0.846107604448452\n",
        "\n",
        "1000 ROWS\n",
        "0.9602335351032997\n",
        "\n",
        "Train Accuracy Score: 0.9690721649484536\n",
        "\n",
        "Test Accuracy Score: 0.852419597234746\n",
        "\n",
        "0.05 SMALLER STOPWARDS\n",
        "1500 ROWS\n",
        "0.9343041056009395\n",
        "\n",
        "Train Accuracy Score: 0.9441688463966807\n",
        "\n",
        "Test Accuracy Score: 0.819\n",
        "\n",
        "1000 ROWS\n",
        "0.8873608065590911\n",
        "\n",
        "Train Accuracy Score: 0.9443298969072165\n",
        "Test Accuracy Score: 0.8211602043883378\n",
        "\n",
        "1000 ROWS, 0.1 SMALLER STOPWARDS\n",
        "0.8631042403030655\n",
        "\n",
        "Train Accuracy Score: 0.8582474226804123\n",
        "\n",
        "Test Accuracy Score: 0.7243763149984972"
      ],
      "metadata": {
        "id": "7an1Uj7tlKsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clf = ensemble.RandomForestClassifier(\n",
        "# #     max_depth=2, random_state=0,\n",
        "# #     n_estimators = 100,\n",
        "# #     n_jobs = -1\n",
        "# )\n",
        "# #clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X,y)\n",
        "train = best.score(X=X,y=y)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)"
      ],
      "metadata": {
        "id": "3Hy54_THlF3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = cv_dataframe[cv_dataframe[\"symbol\"].isnull() == True].drop(['symbol'],axis = 1)\n",
        "X_test[['fi1', 'fi2', 'fi3', 'fi4', 'fi5', 'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004', 'FT0005', 'FT0006',\n",
        "       'FT0007', 'FT0008', 'FT0009']] = combined_data[['fi1', 'fi2', 'fi3', 'fi4', 'fi5', 'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004', 'FT0005', 'FT0006',\n",
        "       'FT0007', 'FT0008', 'FT0009']]\n",
        "y_pred = best.predict(X_test)\n",
        "print(y_pred)\n",
        "j=0\n",
        "for i in X_test.index:\n",
        "    data.at[i, 'symbol' ] = y_pred[j]\n",
        "    j = j +1"
      ],
      "metadata": {
        "id": "EBeQ7JJulUsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()\n",
        "df['cdate'] = df['cdate'].apply(lambda x: pd.to_datetime(x).value)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "df['symbol'] = labelencoder.fit_transform(df['symbol'])\n",
        "df['ext'] = labelencoder.fit_transform(df['ext'])"
      ],
      "metadata": {
        "id": "yvagJSiAlaRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df[['cdate', 'symbol', 'version', 'ext']]\n",
        "df = df[['cdate', 'symbol', 'version', 'ext', 'fi1', 'fi2', 'fi3', 'fi4', 'fi5', 'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004', 'FT0005', 'FT0006',\n",
        "       'FT0007', 'FT0008', 'FT0009']]\n",
        "X = df[df[\"version\"].isnull() == False] \n",
        "y = X['version']\n",
        "X = X.drop(['version'],axis = 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X,y,test_size=0.3)\n",
        "\n",
        "\n",
        "clf = ensemble.RandomForestClassifier(\n",
        "    #max_depth=10, random_state=0,\n",
        "     n_estimators = 1000,\n",
        "     n_jobs = -1\n",
        ")\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X_train,y_train)\n",
        "train = best.score(X=X_train,y=y_train)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)\n",
        "\n",
        "# Get test accuracy\n",
        "    \n",
        "test = best.score(X=X_test,y=y_test)\n",
        "print(\"\\nTest Accuracy Score:\",test)\n",
        "y_pred = best.predict(X_test)\n",
        "print(y_pred)\n",
        "ari = adjusted_rand_score(y_test, y_pred)\n",
        "print(\"\\nAdjusted Rand-Index: %.3f\" % ari)\n",
        "    \n",
        "hom = homogeneity_score(y_test,y_pred)\n",
        "print(\"Homogeneity Score: %.3f\" % hom)\n",
        "    \n",
        "sil = silhouette_score(X_test,y_pred)\n",
        "print(\"Silhouette Score: %.3f\" % sil)\n",
        "    \n",
        "nmi = normalized_mutual_info_score(y_test,y_pred)\n",
        "print(\"Normed Mutual-Info Score: %.3f\" % nmi)\n",
        "\n",
        "    #print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NFq67ZpnlfP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Get train accuracy\n",
        "best = clf.fit(X,y)\n",
        "train = best.score(X=X,y=y)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)\n",
        "\n",
        "X_test = df[df[\"version\"].isnull() == True] .drop(['version'],axis = 1)\n",
        "y_pred = best.predict(X_test)\n",
        "print(y_pred)\n",
        "j=0\n",
        "for i in X_test.index:\n",
        "    data.at[i, 'version' ] = y_pred[j]\n",
        "    j = j +1\n",
        "# Prcentage of data missing after imputation\n",
        "all_data_na = (data.isnull().sum() / len(data)) * 100\n",
        "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
        "missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n",
        "missing_data"
      ],
      "metadata": {
        "id": "i6ZSxqF2lkki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.copy()\n",
        "df['cdate'] = df['cdate'].apply(lambda x: pd.to_datetime(x).value)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "df['symbol'] = labelencoder.fit_transform(df['symbol'])\n",
        "df['ext'] = labelencoder.fit_transform(df['ext'])\n",
        "df['version'] = labelencoder.fit_transform(df['version'])\n",
        "df = df.drop(['description'], axis = 1)\n",
        "\n",
        "\n",
        "# clf = ensemble.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
        "#            max_features='sqrt', max_leaf_nodes=None,\n",
        "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "#            min_samples_leaf=2, min_samples_split=5,\n",
        "#            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=1,\n",
        "#            oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "X = df.iloc[0:6914,:]\n",
        "X['total'] = train_data['total']\n",
        "X = X[X['total'] < 10] # neccesary \n",
        "X = X.fillna(0)\n",
        "#X['total'].hist()\n",
        "\n",
        "\n",
        "#X = df[df[\"total\"].isnull() == False] \n",
        "y = X['total']\n",
        "X = X.drop(['total','id'],axis = 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X,y,test_size=0.3,random_state = 123)\n",
        "\n",
        "#, GradientBoostingRegressor\n",
        "clf = xg.XGBRegressor(objective='reg:squarederror',n_estimators=2500, max_depth=7, eta=0.005, subsample=0.8, colsample_bytree=0.8)\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X_train,y_train)\n",
        "train = best.score(X=X_train,y=y_train)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)\n",
        "\n",
        "# Get test accuracy\n",
        "    \n",
        "test = best.score(X=X_test,y=y_test)\n",
        "print(\"\\nTest Accuracy Score:\",test)\n",
        "    \n",
        "y_pred = best.predict(X_test)\n",
        "print(y_pred)\n",
        "ari = adjusted_rand_score(y_test, y_pred)\n",
        "print(\"\\nAdjusted Rand-Index: %.3f\" % ari)\n",
        "    \n",
        "hom = homogeneity_score(y_test,y_pred)\n",
        "print(\"Homogeneity Score: %.3f\" % hom)\n",
        "    \n",
        "sil = silhouette_score(X_test,y_pred)\n",
        "print(\"Silhouette Score: %.3f\" % sil)\n",
        "    \n",
        "nmi = normalized_mutual_info_score(y_test,y_pred)\n",
        "print(\"Normed Mutual-Info Score: %.3f\" % nmi)"
      ],
      "metadata": {
        "id": "SFmofs6Qlvo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xg.XGBRegressor(objective='reg:squarederror',n_estimators=2500, max_depth=7, eta=0.005, subsample=0.8, colsample_bytree=0.8)\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X,y)\n",
        "train = best.score(X=X,y=y)\n",
        "performance.loc[0,'Train_Accuracy'] = train \n",
        "print(\"\\nTrain Accuracy Score:\",train)\n",
        "\n",
        "X_test = df.iloc[6914:13828,:]\n",
        "X_test = X_test.fillna(0)\n",
        "X_test = X_test.drop(['id'],axis = 1)\n",
        "y_pred = best.predict(X_test)\n",
        "# print(y_pred)\n",
        "pred_data['total'] = y_pred\n",
        "pred_data.to_csv('predictions8.csv',index=False)"
      ],
      "metadata": {
        "id": "tE84fOOxl1HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data = pd.read_csv('../input/stat440-21-project2/pred.csv')\n",
        "test_data = pd.read_csv('../input/stat440-21-project2/Xte.csv')\n",
        "train_data = pd.read_csv('../input/stat440-21-project2/XYtr.csv')"
      ],
      "metadata": {
        "id": "0uXIJTZLmAW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('../input/modeldata/prep_data.csv')\n",
        "data['cdate'] = pd.to_datetime(data['cdate']).values.astype(np.float64)/8.64e+13\n",
        "y = train_data['total'].copy()\n",
        "X = data[['X.sales', 'cdate', 'fee1', 'fee2','fi1', 'fi2', 'fi3', 'fi4', 'fi5',\n",
        "       'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004',\n",
        "       'FT0005', 'FT0006', 'FT0007', 'FT0008', 'FT0009']].copy()\n",
        "X = X.astype(np.float64)\n",
        "X = X.fillna(0)\n",
        "X = X[:6914]\n",
        "xtest = data.copy()\n",
        "X_tes4 = xtest[['X.sales', 'cdate', 'fee1', 'fee2','fi1', 'fi2', 'fi3', 'fi4', 'fi5',\n",
        "       'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004',\n",
        "       'FT0005', 'FT0006', 'FT0007', 'FT0008', 'FT0009']]\n",
        "X_tes4 = xtest[6914:]\n",
        "X_tes4 = X_tes4.drop(['id', 'Unnamed: 0','description','version','symbol','ext'],axis=1)\n",
        "X_tes4 = X_tes4.astype(np.float64)"
      ],
      "metadata": {
        "id": "m8O4ZiAtmC-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitted simple linear regreesion and got a score of 16.4094\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('../input/modeldata/prep_data.csv')\n",
        "data['cdate'] = pd.to_datetime(data['cdate']).values.astype(np.float64)/8.64e+13\n",
        "y = train_data['total'].copy()\n",
        "X = data[['X.sales', 'cdate', 'fee1', 'fee2','fi1', 'fi2', 'fi3', 'fi4', 'fi5',\n",
        "       'fi6', 'fi7', 'FT0000', 'FT0001', 'FT0002', 'FT0003', 'FT0004',\n",
        "       'FT0005', 'FT0006', 'FT0007', 'FT0008', 'FT0009']].copy()\n",
        "X = X[:6914]\n",
        "X = X.fillna(0)\n",
        "X = X.astype(np.float64)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "modelLr = LinearRegression().fit(X, y)"
      ],
      "metadata": {
        "id": "k3AaaPxtmFYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting polynomial regression and got a score of 20.38189\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg = PolynomialFeatures(degree = 2)\n",
        "X_poly = poly_reg.fit_transform(X)\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly,y)\n",
        "pred2= pred_data.copy()\n",
        "pred2['total'] = lin_reg.predict(poly_reg.fit_transform(X_tes4))\n",
        "pred2.to_csv('predpolyR.csv', index = False)"
      ],
      "metadata": {
        "id": "ErDuCQLTmHab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv('../input/modeldata/prep_data.csv')\n",
        "dfxg = data.copy()\n",
        "dfxg['cdate'] = dfxg['cdate'].apply(lambda x: pd.to_datetime(x).value)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "dfxg['symbol'] = labelencoder.fit_transform(dfxg['symbol'])\n",
        "dfxg['ext'] = labelencoder.fit_transform(dfxg['ext'])\n",
        "dfxg['version'] = labelencoder.fit_transform(dfxg['version'])\n",
        "dfxg = dfxg.drop(['description'], axis = 1)\n",
        "\n",
        "\n",
        "# clf = ensemble.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
        "#            max_features='sqrt', max_leaf_nodes=None,\n",
        "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "#            min_samples_leaf=2, min_samples_split=5,\n",
        "#            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=1,\n",
        "#            oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
        "X = dfxg.iloc[0:6914,:]\n",
        "X['total'] = train_data['total']\n",
        "X = X[X['total'] < 10] # neccesary \n",
        "X = X.fillna(0)\n",
        "#X['total'].hist()\n",
        "\n",
        "\n",
        "#X = df[df[\"total\"].isnull() == False] \n",
        "y = X['total']\n",
        "X = X.drop(['total','id'],axis = 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split (X,y,test_size=0.3,random_state = 123)\n",
        "#, GradientBoostingRegressor\n",
        "clf = xg.XGBRegressor(objective='reg:squarederror',n_estimators=2500, max_depth=7, eta=0.005, subsample=0.8, colsample_bytree=0.8)\n",
        "#clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        " # Get train accuracy\n",
        "best = clf.fit(X,y)\n",
        "# train = best.score(X=X_train,y=y_train)\n",
        "# performance.loc[0,'Train_Accuracy'] = train \n",
        "# print(\"\\nTrain Accuracy Score:\",train)"
      ],
      "metadata": {
        "id": "4E07lyJqmKJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_data1 = pred_data.copy()\n",
        "X_tes5 = dfxg.iloc[6914:13828,:]\n",
        "X_tes5 = X_tes5.fillna(0)\n",
        "X_tes5 = X_tes5.drop(['id'],axis = 1)\n",
        "y_pred5 = best.predict(X_tes5)\n",
        "# print(y_pred)\n",
        "pred_data1['total'] = y_pred5\n",
        "pred_data1.to_csv('predXG.csv',index=False)"
      ],
      "metadata": {
        "id": "QHM1QjjkmOfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2['total'] = lin_reg.predict(poly_reg.fit_transform(X_tes4))"
      ],
      "metadata": {
        "id": "dZ2JBO4AmQQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred2.to_csv('predpolyR.csv', index = False)"
      ],
      "metadata": {
        "id": "PwBAlzSWmSMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}